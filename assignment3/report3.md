**contribute:** Bowen Tian did exercise 1, Ruimin Shi did exercise 2.

# Assignment III:

## Exercise 1

### 1. Describe all optimizations you tried regardless of whether you committed to them or abandoned them and whether they improved or hurt performance. 
We use shared memory to reduce the access time since the shared memory is faster than global memory. While in this exercise, the atomic operation is necessary to avoid the race condition.
### 2. Which optimizations you chose in the end and why? 
### 3. How many global memory reads are being performed by your kernel? 
### 4. How many atomic operations are being performed by your kernel? 
### 5. How much shared memory is used in your code?
### 6. How would the value distribution of the input array affect the contention among threads? For instance, what contentions would you expect if every element in the array has the same value?
### 7. Plot a histogram generated by your code and specify your input length, thread block and grid.
### 8. For a input array of 1024 elements, profile with Nvidia Nsight and report Shared Memory Configuration Size and Achieved Occupancy. Did Nvsight report any potential performance issues?

## Exercise 2
### 1. Describe the environment you used, what changes you made to the Makefile, and how you ran the simulation.
### 2. Describe your design of the GPU implementation of mover_PC() briefly. 
### 3. Compare the output of both CPU and GPU implementation to guarantee that your GPU implementations produce correct answers.
### 4. Compare the execution time of your GPU implementation with its CPU version.


